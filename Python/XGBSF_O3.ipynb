{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlW+cUQEVn4CKCAXU1/rbh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/costpetrides/FAIRMODE-WG5/blob/main/Python/XGBSF_O3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7j4rzkx_YwJ",
        "outputId": "579deb76-f9ae-4351-9025-686d95adf70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from cartopy) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.10.0)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.0.7)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from cartopy) (24.2)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3.1->cartopy) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.17.0)\n",
            "Downloading Cartopy-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cartopy\n",
            "Successfully installed cartopy-0.24.1\n"
          ]
        }
      ],
      "source": [
        "pip install cartopy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install netCDF4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcG7XEExDQgg",
        "outputId": "0927ee52-6b2f-4fc2-c489-7e06037c2ab7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.1.31)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from netCDF4) (1.26.4)\n",
            "Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netCDF4\n",
            "Successfully installed cftime-1.6.4.post1 netCDF4-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import netCDF4 as nc\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold, ParameterGrid\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.neighbors import BallTree\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Load CSV Data (Station Measurements) ===\n",
        "csv_file_path = \"baseO3nearest_grid.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Compute Bias (Observed - Modeled)\n",
        "df[\"bias\"] = df[\"SURF_ppb_O3\"] - df[\"nearest_SURF_ppb_O3\"]\n",
        "\n",
        "# === Load NetCDF Data (Grid Model) ===\n",
        "netcdf_path = \"BaseCase_PERT_O3_YEARLY.nc\"\n",
        "dataset = nc.Dataset(netcdf_path, \"r\")\n",
        "\n",
        "lon = dataset.variables[\"lon\"][:]\n",
        "lat = dataset.variables[\"lat\"][:]\n",
        "o3_modeled = dataset.variables[\"SURF_ppb_O3\"][0, :, :]\n",
        "\n",
        "# Convert Degrees to Radians for Haversine Distance\n",
        "lon_rad = np.radians(lon)\n",
        "lat_rad = np.radians(lat)\n",
        "\n",
        "# === Create Meshgrid for Grid Points ===\n",
        "lon_mesh, lat_mesh = np.meshgrid(lon_rad, lat_rad)\n",
        "grid_points = np.column_stack([lat_mesh.ravel(), lon_mesh.ravel()])\n",
        "\n",
        "# === Prepare Station Data (Convert to Radians) ===\n",
        "station_points = np.column_stack([\n",
        "    np.radians(df[\"nearest_grid_lat\"].values),\n",
        "    np.radians(df[\"nearest_grid_lon\"].values)\n",
        "])\n",
        "station_o3 = df[\"nearest_SURF_ppb_O3\"].values  # Modeled O₃ at stations\n",
        "station_bias = df[\"bias\"].values  # Observed bias\n",
        "\n",
        "# === BallTree for Nearest Neighbor Search ===\n",
        "tree = BallTree(station_points, metric=\"haversine\")\n",
        "\n",
        "# === Function: Compute Spatial Features ===\n",
        "def compute_spatial_features(points, station_points, station_o3, station_bias, k=5):\n",
        "    \"\"\"Finds nearest k stations and computes mean, min, max, variance, and IDW-weighted O₃.\"\"\"\n",
        "    dists, idxs = tree.query(points, k=k)\n",
        "\n",
        "    mean_o3 = np.mean(station_o3[idxs], axis=1)\n",
        "    min_o3 = np.min(station_o3[idxs], axis=1)\n",
        "    max_o3 = np.max(station_o3[idxs], axis=1)\n",
        "    var_o3 = np.var(station_o3[idxs], axis=1)\n",
        "    mean_bias = np.mean(station_bias[idxs], axis=1)\n",
        "\n",
        "    weights = 1 / (dists + 1e-6)\n",
        "    weights /= np.sum(weights, axis=1, keepdims=True)\n",
        "\n",
        "    idw_o3 = np.sum(weights * station_o3[idxs], axis=1)\n",
        "\n",
        "    return mean_o3, min_o3, max_o3, var_o3, idw_o3, mean_bias\n",
        "\n",
        "# === Compute Spatial Features for Stations ===\n",
        "mean_o3_s, min_o3_s, max_o3_s, var_o3_s, idw_o3_s, mean_bias_s = compute_spatial_features(\n",
        "    station_points, station_points, station_o3, station_bias, k=5\n",
        ")\n",
        "\n",
        "# Construct Feature Matrix for XGBoost Training\n",
        "X_train = np.column_stack([\n",
        "    df[\"nearest_grid_lon\"].values,\n",
        "    df[\"nearest_grid_lat\"].values,\n",
        "    df[\"nearest_SURF_ppb_O3\"].values,\n",
        "    mean_o3_s, min_o3_s, max_o3_s, var_o3_s, idw_o3_s, mean_bias_s\n",
        "])\n",
        "y_train = station_bias\n",
        "\n",
        "# === Hyperparameter Grid for XGBoost ===\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 300],\n",
        "    \"max_depth\": [10, 15],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"subsample\": [0.8, 1.0],\n",
        "    \"colsample_bytree\": [0.8, 1.0],\n",
        "    \"gamma\": [0, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "param_list = list(ParameterGrid(param_grid))\n",
        "\n",
        "# === Grid Search with RMSE, MAE, R² Calculation ===\n",
        "best_rmse = float(\"inf\")\n",
        "best_params = None\n",
        "results = []\n",
        "\n",
        "print(\"\\nPerforming Hyperparameter Optimization (XGBoost)...\")\n",
        "\n",
        "for params in tqdm(param_list, desc=\"Grid Search Progress\", unit=\"combination\"):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    fold_rmses, fold_maes, fold_r2s = [], [], []\n",
        "\n",
        "    for train_idx, test_idx in kf.split(X_train):\n",
        "        X_tr, X_te = X_train[train_idx], X_train[test_idx]\n",
        "        y_tr, y_te = y_train[train_idx], y_train[test_idx]\n",
        "\n",
        "        model = xgb.XGBRegressor(**params, random_state=42, n_jobs=-1)\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "\n",
        "        fold_rmse = np.sqrt(mean_squared_error(y_te, y_pred))\n",
        "        fold_mae = mean_absolute_error(y_te, y_pred)\n",
        "        fold_r2 = r2_score(y_te, y_pred)\n",
        "\n",
        "        fold_rmses.append(fold_rmse)\n",
        "        fold_maes.append(fold_mae)\n",
        "        fold_r2s.append(fold_r2)\n",
        "\n",
        "    mean_rmse = np.mean(fold_rmses)\n",
        "    mean_mae = np.mean(fold_maes)\n",
        "    mean_r2 = np.mean(fold_r2s)\n",
        "\n",
        "    results.append((params, mean_rmse, mean_mae, mean_r2))\n",
        "\n",
        "    if mean_rmse < best_rmse:\n",
        "        best_rmse = mean_rmse\n",
        "        best_params = params\n",
        "\n",
        "print(f\"\\n Best Parameters Found: {best_params}\")\n",
        "print(f\"Best Model Score (RMSE): {best_rmse:.4f}\")\n",
        "\n",
        "# Train Final XGBoost Model with Best Parameters\n",
        "best_model = xgb.XGBRegressor(**best_params, random_state=42, n_jobs=-1)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# === Compute LOSO RMSE ===\n",
        "loso_predictions, loso_actuals = [], []\n",
        "\n",
        "for i in tqdm(range(len(X_train)), desc=\"LOSO Progress\"):\n",
        "    X_tr = np.delete(X_train, i, axis=0)\n",
        "    y_tr = np.delete(y_train, i)\n",
        "\n",
        "    rf_loso = xgb.XGBRegressor(**best_params, random_state=42, n_jobs=-1)\n",
        "    rf_loso.fit(X_tr, y_tr)\n",
        "\n",
        "    X_test = X_train[i].reshape(1, -1)\n",
        "    y_pred = rf_loso.predict(X_test)[0]\n",
        "\n",
        "    loso_predictions.append(y_pred)\n",
        "    loso_actuals.append(y_train[i])\n",
        "\n",
        "loso_rmse = np.sqrt(mean_squared_error(loso_actuals, loso_predictions))\n",
        "loso_mae = mean_absolute_error(loso_actuals, loso_predictions)\n",
        "loso_r2 = r2_score(loso_actuals, loso_predictions)\n",
        "\n",
        "print(f\"\\nLOSO RMSE: {loso_rmse:.4f}, MAE: {loso_mae:.4f}, R²: {loso_r2:.4f}\")\n",
        "\n",
        "# === Predict Bias on the Grid ===\n",
        "print(\"\\n Predicting Bias on the Grid with Optimized XGBoost...\")\n",
        "interpolated_bias_xgb = best_model.predict(X_train).reshape(o3_modeled.shape)\n",
        "\n",
        "# === Save Bias Correction to NetCDF ===\n",
        "xgb_bias_netcdf_path = \"BaseCase_O3_Y_XGB.nc\"\n",
        "\n",
        "with nc.Dataset(xgb_bias_netcdf_path, \"w\", format=\"NETCDF4\") as bias_nc:\n",
        "    bias_nc.createDimension(\"lat\", lat.shape[0])\n",
        "    bias_nc.createDimension(\"lon\", lon.shape[0])\n",
        "\n",
        "    lat_var = bias_nc.createVariable(\"lat\", \"f4\", (\"lat\",))\n",
        "    lon_var = bias_nc.createVariable(\"lon\", \"f4\", (\"lon\",))\n",
        "    bias_var = bias_nc.createVariable(\"Interpolated_Bias_XGB\", \"f4\", (\"lat\", \"lon\"))\n",
        "\n",
        "    lat_var[:] = lat\n",
        "    lon_var[:] = lon\n",
        "    bias_var[:, :] = interpolated_bias_xgb\n",
        "\n",
        "print(f\"\\n XGBoost Bias Interpolation Saved: {xgb_bias_netcdf_path}\")"
      ],
      "metadata": {
        "id": "0yUhwtQ7DXAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pAabgB-4DXDU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}